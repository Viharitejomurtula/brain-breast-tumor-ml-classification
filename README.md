# Brain and Breast Tumor ML Classification Model

A multimodal medical imaging classification model that uses a custom **TrigConv2D layer** to classify brain and breast tumor MRI scans.

âš ï¸ **Note**: Model training code and preprocessing logic are kept private. This repository contains:
- Public documentation and architecture details
- Dataset summaries and class distributions
- Preprocessed artifacts for demonstration
- Explainability visualizations (Grad-CAM, Integrated Gradients)
- Inference and visualization notebooks

## ğŸ—ï¸ Architecture

The model uses a custom **TrigConv2D** layer that incorporates trigonometric transformations for enhanced feature extraction from medical images. See [src/trigconv2d.py](src/trigconv2d.py) for implementation details.

## ğŸ“ Repository Structure

```
brain-breast-tumor-ml-classification/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Raw image paths (not included in public repo)
â”‚   â”œâ”€â”€ processed/                # Full preprocessed datasets (.npy files)
â”‚   â”œâ”€â”€ brain_data.md             # Brain tumor dataset documentation
â”‚   â”œâ”€â”€ breast_data.md            # Breast cancer dataset documentation
â”‚   â””â”€â”€ class_summary.md          # Class distribution summaries
â”‚
â”œâ”€â”€ artifacts/                    # Small public inference samples
â”‚   â”œâ”€â”€ X_test_sample.npy         # Sample test images (50 samples)
â”‚   â”œâ”€â”€ y_test_sample.npy         # Sample test labels
â”‚   â”œâ”€â”€ label_names.npy           # Class label names
â”‚   â”œâ”€â”€ history.json              # Training history (optional)
â”‚   â””â”€â”€ trigconv_model.keras      # Trained model (if available)
â”‚
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ trigconv2d.py             # Custom TrigConv2D layer
â”‚   â”œâ”€â”€ model_trigconv2d.py       # Model architecture
â”‚   â”œâ”€â”€ explainability.py         # Grad-CAM & Integrated Gradients
â”‚   â”œâ”€â”€ train.py                  # Training script
â”‚   â”œâ”€â”€ eval.py                   # Evaluation utilities
â”‚   â””â”€â”€ preprocessing.py          # Preprocessing stub (private logic not included)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ private_preprocessing.ipynb    # Generates artifacts (NOT in public repo)
â”‚   â”œâ”€â”€ public_visualization.ipynb     # Public demo using artifacts âœ…
â”‚   â””â”€â”€ model_training.ipynb           # Model training notebook
â”‚
â”œâ”€â”€ docs/                         # Additional documentation
â””â”€â”€ README.md                     # This file
```

## ğŸš€ Quick Start

### Prerequisites

```bash
pip install tensorflow numpy matplotlib pandas scikit-learn
```

### Running the Public Visualization Notebook

The public visualization notebook demonstrates the model's capabilities using preprocessed artifacts:

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/brain-breast-tumor-ml-classification.git
   cd brain-breast-tumor-ml-classification
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt  # if available
   ```

3. **Open the public notebook**
   ```bash
   jupyter notebook notebooks/public_visualization.ipynb
   ```

4. **Run all cells**
   - The notebook will load preprocessed sample data from `artifacts/`
   - No raw data or private preprocessing is required
   - Visualizations include:
     - Sample medical images
     - Class distribution analysis
     - Grad-CAM explainability overlays
     - Integrated Gradients attribution maps

## ğŸ“Š What's Included

### Preprocessed Artifacts

The `artifacts/` folder contains:
- **X_test_sample.npy**: 50 preprocessed test images
- **y_test_sample.npy**: Corresponding one-hot encoded labels
- **label_names.npy**: Array of class names
- **history.json**: Training history metrics (if available)
- **trigconv_model.keras**: Trained model weights (if available)

### Explainability

The model includes two explainability techniques:

1. **Grad-CAM (Gradient-weighted Class Activation Mapping)**
   - Highlights which regions of the image influence predictions
   - Visual heatmaps overlaid on original images

2. **Integrated Gradients**
   - Pixel-level attribution showing importance of each pixel
   - More fine-grained than Grad-CAM

See [notebooks/public_visualization.ipynb](notebooks/public_visualization.ipynb) for examples.

## ğŸ”’ Private Components

The following are kept private for security and proprietary reasons:
- Raw medical imaging data
- Full preprocessing pipeline
- Complete training datasets
- Detailed training scripts with hyperparameters

## ğŸ“ˆ Model Performance

Training and evaluation metrics can be visualized in the public notebook if `history.json` is available in the artifacts folder.

## ğŸ¤ Contributing

This is a demonstration repository. For questions or collaboration inquiries, please open an issue.

## ğŸ“„ License

[Add your license here]

## ğŸ”— Related Links

- [TrigConv2D Layer Documentation](src/trigconv2d.py)
- [Explainability Methods](src/explainability.py)
- [Dataset Summaries](data/class_summary.md) 
